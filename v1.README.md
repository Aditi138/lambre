# Morphological Evaluation of NLG

L'AMBRE is a tool to measure the grammatical well-formedness of texts generated by NLG systems. It analyzes the dependency parses of the text using morpho-syntactic rules, and returns a well-formedness score. This tool utilizes the Universal Dependency (UD) project both for extracting rules as well as parsing, and is therefore applicable across languages. See our [EMNLP 2021 paper](https://aclanthology.org/2021.emnlp-main.570/) for more details.

## Try L'AMBRE

Install the requirements using,

```bash
pip install -r requirements.txt
```

To measure well-formedness of a sample Russian corpus, run the following. For examples from more languages, checkout `data/conllu`.

```bash
# obtain a single score for grammatical well-formedness.
# -input: parsed corpus, in CoNLL-U format
# -lg: language code
# -agr: path to file containing agreement rules
# -argstruct: path to file containing case and verbform rules

# (optionally) add --report to print performance w.r.t each morpho-syntactic rule
python scorer/metric.py \
    -input data/conllu/ru.conllu \
    -lg ru \
    -agr rules/agreement_rules.txt \
    -argstruct rules/argstruct_rules_case_verbform.txt
```

---

## Getting Started

To use L'AMBRE directly on raw text corpora, first run the below setup necessary for UD2SUD converter. L'AMBRE uses [Surface-Syntactic Universal Dependencies](https://surfacesyntacticud.github.io/) scheme for dependency parsing.

### Setup

Install [Grew](https://grew.fr/usage/install/) to use the UD2SUD converter. We include a copy of the necessary grs files inside `tools/converter`. For more details on UD2SUD conversion, refer to [surfacesyntacticud](https://github.com/surfacesyntacticud/tools).

```bash
# test installation
grew help
```

Download pre-trained Stanza models that are robust to morphology related errors in input text. Refer to our [Github releases](https://github.com/adithya7/lambre/releases/latest) to download these models.

### Compute L'AMBRE

We provide sample system outputs from WMT'19 shared text under `data/txt`. To compute L'AMBRE on these system outputs, run,

```bash
# example on Russian sample
bash run_lambre.sh ru data/txt/ru.txt
```

For detailed workings of L'AMBRE and additional options, refer to `run_lambre.sh`.

---

## Application: Scoring Machine Translation outputs

We present an application of L'AMBRE to outputs from Machine Translation systems. For instance, to score system outputs from WMT19 news translation shared task,

1. Download system outputs from the [WMT19 metrics shared task](http://ufallab.ms.mff.cuni.cz/~bojar/wmt19/wmt19-submitted-data-v3-txt-minimal.tgz).

```bash
DIR=examples/wmt/data/wmt19
mkdir -p $DIR
wget http://ufallab.ms.mff.cuni.cz/~bojar/wmt19/wmt19-submitted-data-v3-txt-minimal.tgz -P $DIR
tar -zxvf $DIR/wmt19-submitted-data-v3-txt-minimal.tgz -C $DIR
```

2. Generate the SUD parse trees for the system outputs for the translation directions, English&#8594;Czech, English&#8594;German, English&#8594;Finnish, and English&#8594;Russian.

```bash
# use pretrained robust parsing models to generate UD-style trees
# then convert UD to SUD format
bash examples/wmt/parse_wmt19.sh
```

3. Compute L'AMBRE on the obtained parse trees.

```bash
# get an overall corpus-level score
bash examples/wmt/score_wmt19.sh
```

---

## Development

L'AMBRE framework allows for adding support for new languages. To use the tool on a new language, we first need to prepare the grammatical rule set for the language and a parser to inspect these rules. Additionally, all the rule sets are human-readable and are easy to customize for specific downstream applications.

The released rule sets and robust parsers are obtained from UD v2.5. However for development for new languages, consider downloading the latest release from [Universal Dependencies project](https://universaldependencies.org/#download).

```bash
TREEBANK_PATH=parsing/data
mkdir -p $TREEBANK_PATH

# download version v2.8 of UD
wget https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11234/1-3687/ud-treebanks-v2.8.tgz -P $TREEBANK_PATH
tar -zxvf ${TREEBANK_PATH}/ud-treebanks-v2.8.tgz -C $TREEBANK_PATH

# download version v2.8 of SUD
wget https://grew.fr/download/sud-treebanks-v2.8.tgz -P $TREEBANK_PATH --no-check-certificate
tar -zxvf ${TREEBANK_PATH}/sud-treebanks-v2.8.tgz -C $TREEBANK_PATH

```

### Adding a new language

The rules used with L'AMBRE are human-readable and for a guide on understanding these rules, refer to [Understanding Rules](rules/README.md).

We provide tools to automatically extract morpho-syntactic rules for a new language. While the rules can be extracted from any dependency treebank, we recommend using the [Surface-Syntactic dependency treebanks](https://surfacesyntacticud.github.io/data/). However, same tools can be used on the [Universal Dependency treebanks](https://universaldependencies.org/). For more details, refer to [Extracting Rules](extract_rules).

To work with L'AMBRE, dependency parsers need to be robust towards morpho-syntactic errors in text. We use the [Stanza](https://stanfordnlp.github.io/stanza/training.html) to train new morphological taggers and dependency parsers. In addition to our pretrained models for a few selected languages (see [releases](https://github.com/adithya7/lambre/releases/latest)), we provide tools to train parsers for new languages from UD. For more details, refer to [Parsing](parsing).

### Customizing rules

The rule sets in L'AMBRE can be adapted to suit specific downstream application. Refer to the discussion on GEI task in our paper for a few potential directions. For a related study on extracting grammatical agreement rules, including zero-shot settings, check [Chaudhary et al., 2020](https://www.aclweb.org/anthology/2020.emnlp-main.422/).

---

## Reference

If you find this work helpful in your research, consider citing our paper,

```bib
@inproceedings{pratapa-etal-2021-evaluating,
    title = "Evaluating the Morphosyntactic Well-formedness of Generated Texts",
    author = "Pratapa, Adithya  and
      Anastasopoulos, Antonios  and
      Rijhwani, Shruti  and
      Chaudhary, Aditi  and
      Mortensen, David R.  and
      Neubig, Graham  and
      Tsvetkov, Yulia",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.570",
    pages = "7131--7150",
}
```

## Issues

For any issues, questions or requests, please use the [Github Issue Tracker](https://github.com/adithya7/lambre/issues).
